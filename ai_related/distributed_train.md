- [核心概念](#核心概念)
  - [变量解释](#变量解释)
  - [python代码示例](#python代码示例)
  - [启动方式](#启动方式)
- [数据并行（Data Parallel）](#数据并行data-parallel)
- [混合并行（Hybird Parallel）](#混合并行hybird-parallel)


# 核心概念

## 变量解释

| 变量名      | 含义                     | 通俗理解                     |
| ----------- | ------------------------ | ---------------------------- |
| WORLD_SIZE  | 总进程数（全局 GPU 数）  | 一共有多少个“训练进程”在协作 |
| RANK        | 当前进程的全局编号       | 我是第几个进程（从 0 开始）  |
| LOCAL_RANK  | 当前节点（机器）内的编号 | 我在当前机器的第几个 GPU 上  |
| MASTER_ADDR | 主节点 IP 地址           | 负责初始化通信的“主控节点”   |
| MASTER_PORT | 主节点端口               | 进程间通信的端口             |
| NODE_RANK   | 当前节点编号             | 当前机器在集群中的序号       |


假设有 2 台机器，每台 4 张 GPU：

| 机器编号 | GPU 数 | 启动进程数 | NODE_RANK | 对应 RANK 范围 |
| -------- | ------ | ---------- | --------- | -------------- |
| node0    | 4      | 4          | 0         | 0, 1, 2, 3     |
| node1    | 4      | 4          | 1         | 4, 5, 6, 7     |

那么 `WORLD_SIZE=2*4=8`

每个进程会有自己的一组环境变量：

| 机器  | GPU  | RANK | LOCAL_RANK | NODE_RANK |
| ----- | ---- | ---- | ---------- | --------- |
| node0 | GPU0 | 0    | 0          | 0         |
| node0 | GPU1 | 1    | 1          | 0         |
| node0 | GPU2 | 2    | 2          | 0         |
| node0 | GPU3 | 3    | 3          | 0         |
| node1 | GPU0 | 4    | 0          | 1         |
| node1 | GPU1 | 5    | 1          | 1         |
| node1 | GPU2 | 6    | 2          | 1         |
| node1 | GPU3 | 7    | 3          | 1         |

## python代码示例

给一个代码示例：

```python
import torch.distributed as dist

dist.init_process_group(backend="nccl")

world_size = dist.get_world_size()  # 全局进程数
rank = dist.get_rank()              # 当前进程编号
local_rank = int(os.environ["LOCAL_RANK"])  # 当前节点内编号
```

## 启动方式

**典型的启动方式**

用torchrun：

```shell
# 2台机器，每台有4张卡，当前是编号node_rank为0的机器（主机）的启动命令
# 第二台的启动命令就是 --node_rank=1 这个参数改一下即可
CUDA_VISIBLE_DEVICES=0,1,2,3 \
torchrun --nproc_per_node=4 --nnodes=2 \
         --node_rank=0 --master_addr=10.0.0.1 --master_port=29500 \
         train.py
# # 自动生成的变量：
# WORLD_SIZE=8
# NODE_RANK=0
# LOCAL_RANK=0..3
# RANK=0..3
# MASTER_ADDR=10.0.0.1
# MASTER_PORT=29500
```

用slurm/集群调度系统：

```shell
srun -N 2 -n 8 python train.py --launcher slurm
# slurm会自动分配8个任务到2台机器上，通常是前4张卡一台，后4张卡一台，除非设置了 GPU binding 策略
# 自己不用再指定 CUDA_VISIBLE_DEVICES，slurm会自动绑定GPU
```

# 数据并行（Data Parallel）

**核心思想**

- 每张 GPU 拥有一份完整模型副本，
- 处理不同的数据 batch，
- 训练过程中定期同步梯度，使所有模型保持一致。

**工作流程**

1. 模型复制：每个 GPU 拥有相同的模型参数副本。
2. 数据分片：数据集被均匀分割，每张卡处理一部分。
3. 前向传播：每张卡独立计算自己的 loss。
4. 反向传播：每张卡计算自己的梯度。
5. 梯度同步（AllReduce）：
   1. 各 GPU 之间通过 AllReduce 操作交换梯度；
   2. 将所有梯度求平均（或求和）。
6. 参数更新：每张卡用相同的平均梯度更新参数，保证模型完全一致。

**同步时机**

梯度同步在 每个 batch 完成反向传播后 自动执行；
不是每个 epoch；（不然每一步都在朝着不同的方向更新，到最后每个卡的模型权重可能会严重漂移，没办法平均）
保证每步更新后，所有模型权重保持一致。

**通信机制**

使用 AllReduce 操作：每个 GPU 都会与其他 GPU 交换梯度并取平均；
通信库通常使用 NCCL（NVIDIA 集群通信库），支持高速 GPU 直连。

**优缺点**

| 优点                              | 缺点                           |
| --------------------------------- | ------------------------------ |
| 简单易实现（torchrun / DDP 即可） | 模型需能放进单卡显存           |
| 扩展性强，几乎线性加速            | 通信成本较高（每步 AllReduce） |
| 所有模型参数完全一致              | 无法训练超大模型（显存瓶颈）   |

# 混合并行（Hybird Parallel）

**结构组成**

| 并行维度                  | 含义                             | 通信内容               |
| ------------------------- | -------------------------------- | ---------------------- |
| 模型并行 (Model Parallel) | 将模型拆成多部分，分布在多张卡上 | 激活和反向梯度         |
| 数据并行 (Data Parallel)  | 多组模型副本同时训练不同数据     | 梯度 AllReduce（平均） |

**工作原理**

假设模型太大，需要两张 GPU 才能放下：
我们可以用 4 张 GPU，组成两组模型副本：

| 组   | GPU     | 模型分片            | 处理数据 |
| ---- | ------- | ------------------- | -------- |
| 组 A | GPU 0–1 | 模型的一半 + 另一半 | batch_1  |
| 组 B | GPU 2–3 | 模型的一半 + 另一半 | batch_2  |

**训练过程**：

1. **组内通信（模型并行）**
   1. GPU0 计算前半层，输出激活给 GPU1；
   2. GPU1 继续前向传播；
   3. 反向传播时，GPU1 将梯度传回 GPU0；
   4. 组内 GPU 共享激活与梯度，不需要梯度平均。
2. **组间通信（数据并行）**
   1. 每组完成 backward 后，各自得到局部梯度；
   2. 组与组之间做 AllReduce（平均梯度）；
   3. 保证所有模型副本（不同数据组）更新后参数一致。

**通信总结**

| 通信层级             | 通信内容        | 说明           |
| -------------------- | --------------- | -------------- |
| 组内通信（模型内部） | 激活 & 局部梯度 | 用于前后层传递 |
| 组间通信（模型副本） | 梯度 AllReduce  | 确保副本一致   |

**优缺点**

| 优点                              | 缺点                     |
| --------------------------------- | ------------------------ |
| 能训练超大模型（分布存储）        | 通信复杂度高（两层通信） |
| 模型和数据都能扩展                | 代码实现复杂             |
| 可以结合流水线/张量并行进一步扩展 | 调优难度高               |


